{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, csv, face_recognition, copy, math, itertools, os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from model import KeyPointClassifier\n",
    "from pprint import pprint\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Open', 'Close', 'Pointer', 'OK']\n"
     ]
    }
   ],
   "source": [
    " with open('model/keypoint_classifier/keypoint_classifier_label.csv',\n",
    "              encoding='utf-8-sig') as f:\n",
    "        keypoint_classifier_labels = csv.reader(f)\n",
    "        keypoint_classifier_labels = [\n",
    "            row[0] for row in keypoint_classifier_labels\n",
    "        ]\n",
    "print(keypoint_classifier_labels)\n",
    "keypoint_classifier = KeyPointClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "def create_face_encodings(folder= \"facial_images\"):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            tmp_img = face_recognition.load_image_file(os.path.join(folder, filename))\n",
    "            known_face_encodings.append(face_recognition.face_encodings(tmp_img)[0])\n",
    "            known_face_names.append(filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_face_encodings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "# with mp_face_detection.FaceDetection(\n",
    "#     min_detection_confidence=0.5) as face_detection, mp_hands.Hands(\n",
    "#     min_detection_confidence=0.5,\n",
    "#     min_tracking_confidence=0.5, max_num_hands=10) as hands, mp_holistic.Holistic(\n",
    "#     min_detection_confidence=0.5,\n",
    "#     min_tracking_confidence=0.5) as holistic:\n",
    "#  while cap.isOpened():\n",
    "#     success, image = cap.read()\n",
    "#     if not success:\n",
    "#       print(\"Ignoring empty camera frame.\")\n",
    "#       # If loading a video, use 'break' instead of 'continue'.\n",
    "#       continue\n",
    "\n",
    "#     # Flip the image horizontally for a later selfie-view display, and convert\n",
    "#     # the BGR image to RGB.\n",
    "#     image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "#     if process_this_frame:\n",
    "#         # Find all the faces and face encodings in the current frame of video\n",
    "#         face_locations = face_recognition.face_locations(image)\n",
    "#         face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "           \n",
    "#         face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "#         face_names = []\n",
    "#         for i, face_encoding in enumerate(face_encodings):\n",
    "#             nose_x = face_landmarks_list[i]['nose_tip'][0][0]\n",
    "#             nose_y = face_landmarks_list[i]['nose_tip'][0][1]\n",
    "#             # See if the face is a match for the known face(s)\n",
    "#             matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "#             name = \"Unknown\"\n",
    "\n",
    "#             # # If a match was found in known_face_encodings, just use the first one.\n",
    "#             # if True in matches:\n",
    "#             #     first_match_index = matches.index(True)\n",
    "#             #     name = known_face_names[first_match_index]\n",
    "\n",
    "#             # Or instead, use the known face with the smallest distance to the new face\n",
    "#             face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "#             best_match_index = np.argmin(face_distances)\n",
    "#             print(best_match_index)\n",
    "# #             print((1-face_distances[best_match_index])*100)\n",
    "#             print(face_distances)\n",
    "#             if matches[best_match_index]:\n",
    "#                 name = known_face_names[best_match_index]\n",
    "\n",
    "#             face_names.append(name)\n",
    "#             hand_results = hands.process(image)\n",
    "\n",
    "#     process_this_frame = not process_this_frame\n",
    "    \n",
    "    \n",
    "#     # To improve performance, optionally mark the image as not writeable to\n",
    "#     # pass by reference.\n",
    "#     image.flags.writeable = False\n",
    "#     face_results = face_detection.process(image)\n",
    "#     hand_results = hands.process(image)\n",
    "    \n",
    "#     if hand_results.multi_hand_landmarks:\n",
    "#           for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "#             landmark_list = calc_landmark_list(image, hand_landmarks)\n",
    "\n",
    "#             # Conversion to relative coordinates / normalized coordinates\n",
    "#             pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "#             hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "# #             print(keypoint_classifier_labels[hand_sign_id])\n",
    "#             hand_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP].x * image.shape[1]\n",
    "#             hand_y = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP].y * image.shape[0]\n",
    "#             dist = math.sqrt(pow((hand_x-nose_x),2)+pow((hand_y-nose_y),2))\n",
    "#     #         print('distance is')\n",
    "# #             print(dist)\n",
    "#             if(dist<250):\n",
    "#                 print(name, keypoint_classifier_labels[hand_sign_id])\n",
    "#     #         print(hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP].y * image.shape[0])\n",
    "#     #         print(hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP].x * image.shape[1])\n",
    "#     #         print(hand_landmarks)\n",
    "#             mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    \n",
    "    \n",
    "# #     holistic_results = holistic.process(image)\n",
    "\n",
    "#     # Draw the face detection annotations on the image.\n",
    "#     image.flags.writeable = True\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "#     if face_results.detections:\n",
    "#       for detection in face_results.detections:\n",
    "#         mp_drawing.draw_detection(image, detection)\n",
    "        \n",
    "#     cv2.imshow('Face and Hand Detection', image)\n",
    "#     if cv2.waitKey(5) & 0xFF == 27:\n",
    "#       break\n",
    "# # print(mp_holistic.HAND_CONNECTIONS)\n",
    "# cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "print(face_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
